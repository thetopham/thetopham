---
title: NASA SUITS 2026 — TUXEDO AI/VR System
description: Proposal lead and AI/VR systems architect delivering an offline EVA copilot that fuses rover autonomy, AI copilots, and mixed-reality overlays for astronaut safety.
date: "2025-01-15"
url: https://github.com/nasa-suits-challenge/suits-2026
published: true
repository: nasa-suits-challenge/suits-2026
---

![NASA SUITS concept art](https://raw.githubusercontent.com/nasa-suits-challenge/suits-2026/main/docs/tuxedo-hud.png)

## Mission

The NASA SUITS challenge asked us to design the next wave of extravehicular activity (EVA) interfaces for the Artemis program. TUXEDO (Tactile User Experience for Dynamic Operations) is our response—a mixed-reality EVA copilot that keeps astronauts safe even when comms cut out.

I lead the proposal, architecture, and systems design for the 2026 cycle. The objective: merge offline AI copilots, rover autonomy, and AR overlays into a single tool that astronauts can depend on during lunar traverses.

## What I built

- **Offline AI copilots.** Designed an on-device agent stack that runs language and vision models inside mission constraints with deterministic fallbacks.
- **Rover autonomy pipeline.** Integrated sensor fusion, SLAM, and command APIs so rovers and astronauts can share context in real time.
- **Mixed-reality HUD.** Led UX for spatial alerts, telemetry, and procedure checklists rendered inside an Unreal + OpenXR headset.
- **Systems engineering.** Authored the technical volume, interface contracts, and test plan that aligned hardware, software, and operations teams.

## Why it matters

Spacewalks happen far from Earth. By giving crews a resilient AI copilot with AR overlays, we reduce cognitive load, keep them on-plan, and unlock exploration even when network links are delayed.

[Read the proposal](https://github.com/nasa-suits-challenge/suits-2026) · [Follow the team](https://www.linkedin.com/company/nasa-suits-2026)
